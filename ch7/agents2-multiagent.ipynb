{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a399e5c1",
   "metadata": {},
   "source": [
    "# Agents II: multiagent\n",
    "\n",
    "* Multi-agent: Much the same way as a team can accomplish more than a single\n",
    " person, there are problems that can be best tackled by teams of LLM\n",
    " agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11182e98",
   "metadata": {},
   "source": [
    "### Subgraph\n",
    "\n",
    "- Add a node that calls the subgraph directly\n",
    "- Add a node with a function that invokes the subgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58794191",
   "metadata": {},
   "source": [
    "> Share by node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db967de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph, END\n",
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: str # this key is shared with the subgraph\n",
    "\n",
    "class SubgraphState(TypedDict):\n",
    "    foo: str # this key is shared with the parent graph\n",
    "    bar: str\n",
    "\n",
    "# Define subgraph\n",
    "def subgraph_node(state: SubgraphState):\n",
    "    # note that this subgraph node can communicate with the parent graph \n",
    "    # via the shared \"foo\" key\n",
    "    return {\"foo\": state[\"foo\"] + \"bar\"}\n",
    "\n",
    "subgraph_builder = StateGraph(SubgraphState)\n",
    "subgraph_builder.add_node(\"node_subgraph\",subgraph_node)\n",
    "subgraph_builder.add_edge(START, \"node_subgraph\")\n",
    "subgraph = subgraph_builder.compile()\n",
    "\n",
    "# Define parent graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"subgraph\", subgraph)\n",
    "builder.add_edge(START, \"subgraph\")\n",
    "builder.add_edge(\"subgraph\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422a635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subgraph': {'foo': 'Hibar'}}\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "  \"foo\":\"Hi\"\n",
    "}\n",
    "for c in graph.stream(input):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d132b0",
   "metadata": {},
   "source": [
    "> Calling by function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82cfc9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    foo: str\n",
    "\n",
    "class SubgraphState(TypedDict):\n",
    "    # none of these keys are shared with the parent graph state\n",
    "    bar: str\n",
    "    baz: str\n",
    "\n",
    "# Define subgraph\n",
    "def subgraph_node(state: SubgraphState):\n",
    "    return {\"baz\": state[\"baz\"] + \"bar\"}\n",
    "\n",
    "subgraph_builder = StateGraph(SubgraphState)\n",
    "subgraph_builder.add_node(\"the_subgraph\",subgraph_node)\n",
    "subgraph_builder.add_edge(START, \"the_subgraph\")\n",
    "subgraph = subgraph_builder.compile()\n",
    "\n",
    "# Define parent graph\n",
    "def node(state: State):\n",
    "    # transform the state to the subgraph state\n",
    "    response = subgraph.invoke({\"baz\": state[\"foo\"]})\n",
    "    # transform response back to the parent state\n",
    "    return {\"foo\": response[\"baz\"]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "# note that we are using `node` function instead of a compiled subgraph\n",
    "builder.add_node(\"main\",node)\n",
    "builder.add_edge(START, \"main\")\n",
    "builder.add_edge(\"main\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44de08e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main': {'foo': 'Hibar'}}\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "  \"foo\":\"Hi\"\n",
    "}\n",
    "for c in graph.stream(input):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a958957",
   "metadata": {},
   "source": [
    "## Multi-agent\n",
    "\n",
    "* Supervisor Architecture\n",
    "* Network architecture\n",
    "* Hierachical architecture\n",
    "* Custom workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1cd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_ollama import ChatOllama\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class SupervisorDecision(BaseModel):\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
    "\n",
    "model = ChatOllama(model=\"llama3.2:1b\", temperature=0)\n",
    "model = model.with_structured_output(SupervisorDecision)\n",
    "\n",
    "agents = [\"researcher\", \"coder\"]\n",
    "\n",
    "system_prompt_part_1 = f\"\"\"You are a supervisor tasked with managing a \n",
    "conversation between the following workers: {agents}. Given the following user \n",
    "request, respond with the worker to act next. Each worker will perform a\n",
    "task and respond with their results and status. When finished,\n",
    "respond with FINISH.\"\"\"\n",
    "\n",
    "system_prompt_part_2 = f\"\"\"Given the conversation above, who should act next? Or \n",
    "    should we FINISH? Select one of: {', '.join(agents)}, FINISH\"\"\"\n",
    "\n",
    "def supervisor(state):\n",
    "    messages = [\n",
    "        (\"system\", system_prompt_part_1),\n",
    "        *state[\"messages\"],\n",
    "        (\"system\", \tsystem_prompt_part_2)\n",
    "    ]\n",
    "    state[\"next\"] = model.invoke(messages) \n",
    "    return state[\"next\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d89011a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Annotated, TypedDict\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "model = ChatOllama(model=\"llama3.2:1b\", temperature=0)\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
    "\n",
    "def researcher(state: AgentState):\n",
    "    response = model.invoke(\"Researching...\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def coder(state: AgentState):\n",
    "    response = model.invoke(\"Coding...\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(supervisor)\n",
    "builder.add_node(researcher)\n",
    "builder.add_node(coder)\n",
    "\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "# route to one of the agents or exit based on the supervisor's decision\n",
    "builder.add_conditional_edges(\"supervisor\", lambda state: state[\"next\"])\n",
    "builder.add_edge(\"researcher\", \"supervisor\")\n",
    "builder.add_edge(\"coder\", \"supervisor\")\n",
    "\n",
    "supervisor = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "716ee428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task supervisor with path ('__pregel_pull', 'supervisor') wrote to unknown channel branch:to:FINISH, ignoring it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "for c in supervisor.stream(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(\"I need the code for Grounding DINO\")],\n",
    "        \"next\":\"FINISH\"\n",
    "    }\n",
    "    ):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a601a08",
   "metadata": {},
   "source": [
    ">> Pending search on langchain doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203f48e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
