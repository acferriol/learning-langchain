{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11aeeb70",
   "metadata": {},
   "source": [
    "# Apps Architecture\n",
    "\n",
    "* Tradeoff Agency-Reliability\n",
    "* Decisions\n",
    "    * Output\n",
    "    * Next Step\n",
    "    * Steps Availables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1fa81",
   "metadata": {},
   "source": [
    "## LLM Cognitive Architectures\n",
    "\n",
    "* Code\n",
    "* LLM Call\n",
    "* Chain\n",
    "* Router\n",
    "* State Machine\n",
    "* Autonomous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb49351",
   "metadata": {},
   "source": [
    "### LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b8a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "model = ChatOllama(model=\"qwen:0.5b\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` \n",
    "    # function in the annotation defines how this state should \n",
    "    # be updated (in this case, it appends new messages to the \n",
    "    # list, rather than replacing the previous messages)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def chatbot(state: State):\n",
    "    answer = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "builder.add_edge(START, 'chatbot')\n",
    "builder.add_edge('chatbot', END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6152385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---\\nconfig:\\n  flowchart:\\n    curve: linear\\n---\\ngraph TD;\\n\\t__start__([<p>__start__</p>]):::first\\n\\tchatbot(chatbot)\\n\\t__end__([<p>__end__</p>]):::last\\n\\t__start__ --> chatbot;\\n\\tchatbot --> __end__;\\n\\tclassDef default fill:#f2f0ff,line-height:1.2\\n\\tclassDef first fill-opacity:0\\n\\tclassDef last fill:#bfb6fc\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_graph().draw_mermaid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336053bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': [AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'qwen:0.5b', 'created_at': '2025-08-07T18:46:20.6495927Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1804385800, 'load_duration': 1505442500, 'prompt_eval_count': 10, 'prompt_eval_duration': 87106800, 'eval_count': 10, 'eval_duration': 209551500, 'model_name': 'qwen:0.5b'}, id='run--7011b60f-825e-4c8c-89da-63c5776ef8d7-0', usage_metadata={'input_tokens': 10, 'output_tokens': 10, 'total_tokens': 20})]}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "input = {\"messages\": [HumanMessage('hi!')]}\n",
    "for chunk in graph.stream(input):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b9cea",
   "metadata": {},
   "source": [
    "### Chain (Flow Engineering) with extra steps !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "d9718cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, List, Tuple\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_community.tools import QuerySQLDatabaseTool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "# useful to generate SQL query\n",
    "model_low_temp = ChatOllama(model=\"qwen:0.5b\",temperature=0)\n",
    "# useful to generate natural language outputs\n",
    "model_high_temp = ChatOllama(model=\"qwen:0.5b\",temperature=0.8)\n",
    "# summarize  content from table\n",
    "model_summarizer = ChatOllama(model=\"qwen:0.5b\", temperature=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "73d21fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # to track conversation history\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # input\n",
    "    user_query: str\n",
    "    # output\n",
    "    sql_query: str\n",
    "    sql_explanation: str\n",
    "    query_result: List[Tuple]\n",
    "    result_summary: str\n",
    "    \n",
    "\n",
    "class Input(TypedDict):\n",
    "    user_query: str\n",
    "\n",
    "class Output(TypedDict):\n",
    "    sql_query: str\n",
    "    sql_explanation: str\n",
    "    query_result: List[Tuple]\n",
    "    result_summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c6c6691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prompt = SystemMessage(\n",
    "    \"\"\"Given an input question create a SQL query according to question. Only return SQL query nothing else\"\"\"\n",
    ")\n",
    "\n",
    "def generate_sql(state: State) -> State:\n",
    "    user_message = HumanMessage(state[\"user_query\"])\n",
    "    messages = [generate_prompt, *state[\"messages\"], user_message]\n",
    "    res = model_low_temp.invoke(messages)\n",
    "    return {\n",
    "        \"sql_query\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": [user_message, res],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "73deb0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=2,\n",
    "    strategy=\"last\",\n",
    "    token_counter=len, #Each message is a token\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    ")\n",
    "\n",
    "explain_prompt = SystemMessage(\n",
    "    \"You are an assitant, given an SQL code input return a NON EMPTY explanation for that code\"\n",
    ")\n",
    "\n",
    "def explain_sql(state: State) -> State:\n",
    "    messages = [\n",
    "        explain_prompt,\n",
    "        # contains user's query and SQL query from prev step\n",
    "        *state[\"messages\"],\n",
    "    ]\n",
    "    msgs = trimmer.invoke(messages)\n",
    "    res = model_high_temp.invoke(msgs)\n",
    "    return {\n",
    "        \"sql_explanation\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": res,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "547d2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_prompt = SystemMessage(\n",
    "    \"Given a list of tuples from a database summarize its content\"\n",
    ")\n",
    "def summarize_result(state: State) -> State:\n",
    "    query = state[\"sql_query\"]\n",
    "    db = SQLDatabase.from_uri(\"sqlite:///../data/sample.db\")\n",
    "    execute_query = QuerySQLDatabaseTool(db=db)\n",
    "    table = execute_query.invoke(input=query)\n",
    "    res = model_summarizer.invoke([summarize_prompt, table])\n",
    "    return {\n",
    "        \"query_result\": table,\n",
    "        \"result_summary\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": res,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4f591292",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State, input_schema=Input, output_schema=Output)\n",
    "builder.add_node(\"generate_sql\", generate_sql)\n",
    "builder.add_node(\"explain_sql\", explain_sql)\n",
    "builder.add_node(\"summarize_result\", summarize_result)\n",
    "builder.add_edge(START, \"generate_sql\")\n",
    "builder.add_edge(\"generate_sql\", \"explain_sql\")\n",
    "builder.add_edge(\"generate_sql\", \"summarize_result\")\n",
    "builder.add_edge(\"explain_sql\", END)\n",
    "builder.add_edge(\"summarize_result\", END)\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "70ff0a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": 1,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "2aaf94ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_query': 'SELECT * FROM users;',\n",
       " 'sql_explanation': '',\n",
       " 'query_result': \"[(1, 'acf', '123'), (2, 'ale', '456'), (3, 'abc', '789'), (4, 'zyx', '987')]\",\n",
       " 'result_summary': '```sql\\nSELECT * FROM table_name;\\n```\\n\\nThis SQL statement will select all the columns from the `table_name` column.'}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\n",
    "  \"user_query\": \"List the users\"\n",
    "}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ce4799da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "1f073cb3-5661-64df-8002-bc64fa77f5d3\n",
      "\n",
      "('explain_sql', 'summarize_result')\n",
      "1f073cb3-49d5-6962-8001-be457012c449\n",
      "\n",
      "('generate_sql',)\n",
      "1f073cb3-45e1-6f28-8000-daedfbecb3ce\n",
      "\n",
      "('__start__',)\n",
      "1f073cb3-45df-6877-bfff-86436f19618f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "states = list(graph.get_state_history(config))\n",
    "\n",
    "for state in states:\n",
    "    print(state.next)\n",
    "    print(state.config[\"configurable\"][\"checkpoint_id\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55cae3",
   "metadata": {},
   "source": [
    "### Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "4861ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.vectorstores.in_memory import InMemoryVectorStore\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "a4d10d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"qwen:0.5b\")\n",
    "# useful to generate SQL query\n",
    "model_low_temp = ChatOllama(model=\"qwen:0.5b\" ,temperature=0)\n",
    "# useful to generate natural language outputs\n",
    "model_high_temp = ChatOllama(model=\"qwen:0.5b\",temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e69555cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # to track conversation history\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # input\n",
    "    user_query: str\n",
    "    # output\n",
    "    domain: Literal[\"Alejandro Cespon\", \"Greek Philosophy\"]\n",
    "    documents: list[Document]\n",
    "    answer: str\n",
    "\n",
    "class Input(TypedDict):\n",
    "    user_query: str\n",
    "\n",
    "class Output(TypedDict):\n",
    "    documents: list[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454bf019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "pdfloader = PyPDFLoader('../data/test.pdf')\n",
    "alejandro_doc = pdfloader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "splitted_docs = splitter.split_documents(alejandro_doc)\n",
    "\n",
    "alejandro_records_store = InMemoryVectorStore.from_documents(splitted_docs, embeddings)\n",
    "alejandro_records_retriever = alejandro_records_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "43412bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "raw_documents = TextLoader('../data/philotest.txt', encoding=\"utf-8\").load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, \n",
    "    chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "philo_records_store = InMemoryVectorStore.from_documents(documents, embeddings)\n",
    "philo_records_retriever = philo_records_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "503e7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = SystemMessage(\n",
    "    \"\"\"Output only one word (alejandro or philosophy)\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "4d245182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_node(state: State) -> State:\n",
    "    user_message = HumanMessage(state[\"user_query\"])\n",
    "    messages = [router_prompt, *state[\"messages\"], user_message]\n",
    "    res = model_low_temp.invoke(messages)\n",
    "    return {\n",
    "        \"domain\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": [user_message, res],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "c7108f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "\n",
    "def pick_retriever(\n",
    "    state: State,\n",
    ") -> Literal[\"retrieve_alejandro\", \"retrieve_philosophy\"]:\n",
    "    domain_embedding = embeddings.embed_query(state['domain'])\n",
    "    alejandro_embedding = embeddings.embed_query(\"Alejandro Cespón Ferriol, professor, doctoral research, developer\")\n",
    "    philosophy_embeddings = embeddings.embed_query(\"Greek Philosophy, Nature, Origin, Math, Platon, Socrates\")\n",
    "    alejandro_sim = cosine_similarity([domain_embedding],[alejandro_embedding])\n",
    "    philosophy_sim = cosine_similarity([domain_embedding], [philosophy_embeddings])\n",
    "\n",
    "    print(\"Alejandro Sim\")\n",
    "    print(alejandro_sim)\n",
    "    print(\"Philo Sim\")\n",
    "    print(philosophy_sim)\n",
    "    if alejandro_sim > philosophy_sim:\n",
    "        state[\"domain\"] = \"alejandro\"\n",
    "        return \"retrieve_alejandro\"\n",
    "    else:\n",
    "        state[\"domain\"] = \"philosophy\"\n",
    "        return \"retrieve_philosophy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "16f4bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_alejandro(state: State) -> State:\n",
    "    documents = alejandro_records_retriever.invoke(state[\"user_query\"])\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "cd693a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_philosophy(state: State) -> State:\n",
    "    documents = philo_records_retriever.invoke(state[\"user_query\"])\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "53afdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alejandro_prompt = SystemMessage(\n",
    "    \"\"\"You are a helpful chatbot who answers questions based on the \n",
    "        curriculum of Alejandro Cespon Ferriol.\"\"\"\n",
    ")\n",
    "\n",
    "philo_prompt = SystemMessage(\n",
    "    \"\"\"You are a helpful chatbot who answers questions about Greek Philosophy.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "a2f4169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: State) -> State:\n",
    "    if state[\"domain\"] == \"alejandro\":\n",
    "        prompt = alejandro_prompt\n",
    "    else:\n",
    "        prompt = philo_prompt\n",
    "    docs = state[\"documents\"]\n",
    "    messages = [\n",
    "        prompt,\n",
    "        *state[\"messages\"],\n",
    "        HumanMessage(f\"Documents: { docs }\"),\n",
    "    ]\n",
    "    res = model_high_temp.invoke(messages)\n",
    "    return {\n",
    "        \"answer\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": res,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "c8ad9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State, input_schema=Input, output_schema=Output)\n",
    "builder.add_node(\"router\", router_node)\n",
    "builder.add_node(\"retrieve_alejandro\", retrieve_alejandro)\n",
    "builder.add_node(\"retrieve_philosophy\", retrieve_philosophy)\n",
    "builder.add_node(\"generate_answer\", generate_answer)\n",
    "builder.add_edge(START, \"router\")\n",
    "builder.add_conditional_edges(\"router\", pick_retriever)\n",
    "builder.add_edge(\"retrieve_alejandro\", \"generate_answer\")\n",
    "builder.add_edge(\"retrieve_philosophy\", \"generate_answer\")\n",
    "builder.add_edge(\"generate_answer\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "c907a01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alejandro Sim\n",
      "[[0.54729499]]\n",
      "Philo Sim\n",
      "[[0.50112488]]\n",
      "{'router': {'domain': 'Doctoral researcher.', 'messages': [HumanMessage(content='Who is doctoral researcher?', additional_kwargs={}, response_metadata={}, id='913579fd-76df-41ad-b54e-6f5112333ecf'), AIMessage(content='Doctoral researcher.', additional_kwargs={}, response_metadata={'model': 'qwen:0.5b', 'created_at': '2025-08-07T21:15:05.851385Z', 'done': True, 'done_reason': 'stop', 'total_duration': 719962800, 'load_duration': 74659800, 'prompt_eval_count': 28, 'prompt_eval_duration': 285308600, 'eval_count': 5, 'eval_duration': 338067800, 'model_name': 'qwen:0.5b'}, id='run--1e10100c-54b8-4bf9-b31d-803219bd16e9-0', usage_metadata={'input_tokens': 28, 'output_tokens': 5, 'total_tokens': 33})]}}\n",
      "{'retrieve_alejandro': {'documents': [Document(id='5f8bd043-f265-4ac8-9bb5-026479c65ddf', metadata={'producer': 'MiKTeX-dvipdfmx (20220710)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-07-10T17:14:12-04:00', 'source': '../data/test.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='VocationalInstituteofExactScience”ErnestoGuevara” VillaClara,Cuba\\nHiGHSCHOOL Sep. 2015‑Jun. 2018\\n• Mathematicshighperformingstudent\\nSkills\\nBack‑end Django,PostgreSQL,API‑REST,PlayFramework\\nFront‑end HTML5,CSS3,JavaScript,Bootstrap\\nProgrammingLanguages Python,Java,C++,SQL,Scala\\nAIandMachineLearning Numpy,Pandas,Matplotlib,Scikit‑learn,Tensorflow,PyTorch,PySpark,LangChain\\nOthers Git,LaTex,Markdown,JupyterNotebooks,Storytelling\\nLanguages Spanish(native),English(B1)\\nResearch MachineLearning,DistributedConvexOptimization,GANs,FederatedLearning,XAI,LLMs\\nExperience\\nAndalusianInteruniversityInstituteofDataScienceandComputationalIntelligence Granada,Spain\\nRESEARCHER Jan. 2025‑Present\\n• ResearchonXAIandLLMs\\n• Profile: https://dasci.es/investigador/alejandro‑cespon‑ferriol/\\nUCLVComputerScienceDepartment&InformaticsInvestigationCenter VillaClara,Cuba\\nPROFESSOR&RESEARCHER Dec. 2023‑Present\\n• TeachDiscreteMathematicsandNumericalAnalysisinBachelor’sDegreeonComputerScience.'), Document(id='921bc819-42ba-48dc-8af4-6bbdb54babee', metadata={'producer': 'MiKTeX-dvipdfmx (20220710)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-07-10T17:14:12-04:00', 'source': '../data/test.pdf', 'total_pages': 4, 'page': 1, 'page_label': '2'}, page_content='Memberships\\nORGANiZATiONS\\n2024‑\\nPresent Member,InternationalAssociationforPatternRecognition Global\\n2024‑\\nPresent Member,NationalAssociationforPatternRecognition Cuba\\n2024‑\\nPresent Member,MathematicandComputationCubanSociety Cuba\\n2025‑\\nPresent Member,YoungResearchersNetwork“PhDJoséLuisGarcíaCuevas´´ Cuba\\nPROJECTS\\n2024‑\\nPresent\\nMember,Developmentofmethodsandsoftwaretoolsforfederatedlearningandgenerativeneural\\nnetworksfortheefficientandsafeuseofrestrictedmedicalimages(Automation,RoboticsandArtificial\\nIntelligenceProgram)\\nCuba‑Belarus\\n2024‑\\nPresent\\nMember,TheoreticalcontributionstoAIinhandlingproblemswithcomplexdata(Automation,Robotics\\nandArtificialIntelligenceProgram) Cuba\\nHonors,Events&Awards\\nINTERNATiONALAWARDS\\n2024 Participant,19thInternationalConventionandFairINFORMATICA2024 LaHabana,Cuba\\n2023 Participant,IVInternationalScientificConventionUCLV2023 CayoSantaMaría,\\nCuba\\n2021 Participant,IberoamericanMathematicsOlympiad Online\\nNATiONALAWARDS'), Document(id='f7d202bf-b7f7-451d-b234-78a290dad130', metadata={'producer': 'MiKTeX-dvipdfmx (20220710)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-07-10T17:14:12-04:00', 'source': '../data/test.pdf', 'total_pages': 4, 'page': 2, 'page_label': '3'}, page_content='Certificates\\n2025 EthicsandIntegrityinResearchandPublication ,GranadaUniversity\\n2025 WritingscientifictextswithLaTeXandversioncontrolwithGit ,GranadaUniversity\\n2025 CommunicateFools!,GranadaUniversity\\n2024 DataVisualization,Kaggle\\n2024 ArtificialIntelligencein360 ,GranadaUniversity\\n2024 IntrotoDeepLearning ,Kaggle\\n2024 IntermediateMachineLearning ,Kaggle\\n2023 Pandas,Kaggle\\n2023 IntrotoMachineLearning ,Kaggle\\n2022 Python,Kaggle\\n2022 IntrotoProgramming ,Kaggle\\n2022 ElementsofAI ,MinnaLearn\\nWriting\\nDevelopmentofaDistributedOutlierDetectionMethodbasedonTheAlternating\\nDirectionMethodofMultipliers\\nJournalofAutomation,Mobile\\nRoboticsandIntelligentSystems\\n(JAMRIS)\\nWRiTER/CONTRiBUTOR 2025\\n• AlejandroCesponFerriol,HéctorR.González,CarlosA.MorellPerez\\n• DOI:https://doi.org/10.14313/jamris‑2025‑009\\nDevelopmentofaDistributedOutlierDetectionMethodbasedonTheAlternating\\nDirectionMethodofMultipliers\\nEventMemories19thInternational\\nConventionandFairINFORMATICA\\nWRiTER/CONTRiBUTOR 2024'), Document(id='0fdcf9dd-bd66-44fd-9307-845345ec5ae1', metadata={'producer': 'MiKTeX-dvipdfmx (20220710)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-07-10T17:14:12-04:00', 'source': '../data/test.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='Alejandro Cespón\\nARTiFiCiALINTELLiGENCERESEARCHER · SOFTWAREMiDDEVELOPER\\nSanta Clara, Villa Clara, Cuba\\nć cesponalejandro@gmail.com | ^ acferriol | ] alejandro-cespon-b36771209 | Ȉ 0000-0002-8584-6958 | Ƹ Alejandro-Cespon-Ferriol | Ǒ alejandrocespon\\n| ŵ Alejandro Cespón Ferriol | 24 years\\n“Lifeisthis...,Ilikethis”\\nHarveySpecter\\nEducation\\nGranadaUniversity Granada,Spain\\nPHDONCOMPUTERSCiENCE Nov. 2024‑Present\\n• DoctoralProgrammeinInformationandCommunicationTechnologies(B25/56/1).\\nUCLV(CentralUniversity”MartaAbreu”ofLasVillas) VillaClara,Cuba\\nMASTERONCOMPUTERSCiENCE Dec. 2023‑Sept. 2024\\n• Studyingfromundergraduatebyaspecialtrainingplan\\nUCLV(CentralUniversity”MartaAbreu”ofLasVillas) VillaClara,Cuba\\nB.S.ONCOMPUTERSCiENCE Sep. 2019‑Dec. 2023\\n• GotmydirectadmissionbybelongingtoMathematicsHigh‑SchoolCubanPreselection.\\nVocationalInstituteofExactScience”ErnestoGuevara” VillaClara,Cuba\\nHiGHSCHOOL Sep. 2015‑Jun. 2018\\n• Mathematicshighperformingstudent\\nSkills')]}}\n",
      "{'generate_answer': {'answer': 'The given text contains various phrases and clauses that are related to the topic of life on Earth, specifically focusing on computer science. \\n\\nSome possible phrases or clauses include:\\n\\n- Life is a journey.\\n- Technology is the key to success.\\n- The future belongs to those who believe in it.\\n- In a world where progress has become too fast for some, there remains the power and ability to change the course of history.', 'messages': AIMessage(content='The given text contains various phrases and clauses that are related to the topic of life on Earth, specifically focusing on computer science. \\n\\nSome possible phrases or clauses include:\\n\\n- Life is a journey.\\n- Technology is the key to success.\\n- The future belongs to those who believe in it.\\n- In a world where progress has become too fast for some, there remains the power and ability to change the course of history.', additional_kwargs={}, response_metadata={'model': 'qwen:0.5b', 'created_at': '2025-08-07T21:15:40.249579Z', 'done': True, 'done_reason': 'stop', 'total_duration': 33702470300, 'load_duration': 42572400, 'prompt_eval_count': 2048, 'prompt_eval_duration': 29305575200, 'eval_count': 85, 'eval_duration': 4278634900, 'model_name': 'qwen:0.5b'}, id='run--a52ea8eb-cd8f-4e6f-9f50-c981344756ee-0', usage_metadata={'input_tokens': 2048, 'output_tokens': 85, 'total_tokens': 2133})}}\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"user_query\": \"Who is doctoral researcher?\"\n",
    "}\n",
    "for c in graph.stream(input):\n",
    "    print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
