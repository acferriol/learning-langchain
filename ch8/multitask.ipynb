{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c99439d",
   "metadata": {},
   "source": [
    "# Multitasking LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a059506",
   "metadata": {},
   "source": [
    "> - Refuse concurrent inputs\n",
    ">> Any input received while processing a previous one is rejected. This is the simplest strategy, but unlikely to cover all needs, as it effectively means handing off concurrency management to the caller.\n",
    "\n",
    "> - Handle independently\n",
    ">> Another simple option is to treat any new input as an independent invocation, creating a new thread (a container for remembering state) and producing output in that context.\n",
    "\n",
    "> - Queue concurrent inputs\n",
    ">> Any input received while processing a previous one is queued up and handled when the current one is finished.\n",
    "\n",
    "> - Interrupt\n",
    ">> When a new input is received while another is being processed, abandon processing of the current one and restart the chain with the new input.\n",
    "\n",
    "> - Fork and merge\n",
    ">> Another option is to handle new input in parallel, forking the state of the thread as it is when the new input is received and merging the final states as inputs finish being handled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3abce8e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
