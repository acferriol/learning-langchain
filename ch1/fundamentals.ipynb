{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823c4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get apikey\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "apikey = os.getenv(\"AI-API-KEY\")\n",
    "model_sel = os.getenv(\"MODEL\")\n",
    "url = os.getenv(\"BASE-URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d93cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf338a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    base_url=url,\n",
    "    api_key=apikey,\n",
    "    model=model_sel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b3c8e3",
   "metadata": {},
   "source": [
    "### Messages Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96318775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Paris!!!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 30, 'total_tokens': 33, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'mistralai/mistral-small-3.2-24b-instruct:free', 'system_fingerprint': None, 'id': 'gen-1753275965-tpI1U61K81bKtNDHg7Iv', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--eb1fd8f3-0578-4940-97bc-9b68f5d44360-0', usage_metadata={'input_tokens': 30, 'output_tokens': 3, 'total_tokens': 33, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_message = SystemMessage('''You are a helpful assistant that responds to questions with three \n",
    "        exclamation marks.'''\n",
    ")\n",
    "human_message = HumanMessage('What is the capital of France?')\n",
    "\n",
    "model.invoke([sys_message, human_message])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0bbbc",
   "metadata": {},
   "source": [
    "### Reusable Prompts (Templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cbb7dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Answer the question based on the\\n    context below. If the question cannot be answered using the information \\n    provided, answer with \"I don\\'t know\".\\n\\nContext: The most recent advancements in NLP are being driven by Large \\n        Language Models (LLMs). These models outperform their smaller \\n        counterparts and have become invaluable for developers who are creating \\n        applications with NLP capabilities. Developers can tap into these \\n        models through Hugging Face\\'s `transformers` library, or by utilizing \\n        OpenAI and Cohere\\'s offerings through the `openai` and `cohere` \\n        libraries, respectively.\\n\\nQuestion: Which model providers offer LLMs?\\n\\nAnswer: ')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"\"\"Answer the question based on the\n",
    "    context below. If the question cannot be answered using the information \n",
    "    provided, answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\")\n",
    "\n",
    "template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large \n",
    "        Language Models (LLMs). These models outperform their smaller \n",
    "        counterparts and have become invaluable for developers who are creating \n",
    "        applications with NLP capabilities. Developers can tap into these \n",
    "        models through Hugging Face's `transformers` library, or by utilizing \n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere` \n",
    "        libraries, respectively.\"\"\",\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339040ac",
   "metadata": {},
   "source": [
    "context and question are parameters, prompt is dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1abcf61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate.from_template(\"\"\"Answer the question based on the \n",
    "    context below. If the question cannot be answered using the information \n",
    "    provided, answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=url,\n",
    "    api_key=apikey,\n",
    "    model=model_sel\n",
    ")\n",
    "\n",
    "# `prompt` and `completion` are the results of using template and model once\n",
    "\n",
    "prompt = template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large\n",
    "        Language Models (LLMs). These models outperform their smaller \n",
    "        counterparts and have become invaluable for developers who are creating \n",
    "        applications with NLP capabilities. Developers can tap into these \n",
    "        models through Hugging Face's `transformers` library, or by utilizing \n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere` \n",
    "        libraries, respectively.\"\"\",\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "})\n",
    "\n",
    "completion = model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52c6a01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The model providers that offer LLMs mentioned in the context are Hugging Face, OpenAI, and Cohere.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbc4c1f",
   "metadata": {},
   "source": [
    "### Prompt templates + Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1e6f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''Answer the question based on the context below. If the \n",
    "        question cannot be answered using the information provided, answer with \n",
    "        \"I don\\'t know\".'''),\n",
    "    ('human', 'Context: {context}'),\n",
    "    ('human', 'Question: {question}'),\n",
    "])\n",
    "\n",
    "prompt = template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large \n",
    "        Language Models (LLMs). These models outperform their smaller \n",
    "        counterparts and have become invaluable for developers who are creating \n",
    "        applications with NLP capabilities. Developers can tap into these \n",
    "        models through Hugging Face's `transformers` library, or by utilizing \n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere` \n",
    "        libraries, respectively.\"\"\",\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d537ba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Answer the question based on the context below. If the \\n        question cannot be answered using the information provided, answer with \\n        \"I don\\'t know\".', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Context: The most recent advancements in NLP are being driven by Large \\n        Language Models (LLMs). These models outperform their smaller \\n        counterparts and have become invaluable for developers who are creating \\n        applications with NLP capabilities. Developers can tap into these \\n        models through Hugging Face's `transformers` library, or by utilizing \\n        OpenAI and Cohere's offerings through the `openai` and `cohere` \\n        libraries, respectively.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Question: Which model providers offer LLMs?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86d0675e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Based on the context provided, the model providers that offer LLMs are Hugging Face, OpenAI, and Cohere.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 152, 'total_tokens': 178, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'mistralai/mistral-small-3.2-24b-instruct:free', 'system_fingerprint': None, 'id': 'gen-1753276766-Tpr2wO0eGw1euikVYDHE', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--52858b6b-7f92-40b5-8311-41ff83eae63c-0', usage_metadata={'input_tokens': 152, 'output_tokens': 26, 'total_tokens': 178, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342ed7c",
   "metadata": {},
   "source": [
    "### Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9fdace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pydantic\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    '''An answer to the user's question along with justification for the \n",
    "        answer.'''\n",
    "    answer: str\n",
    "    '''The answer to the user's question'''\n",
    "    justification: str\n",
    "    '''Justification for the answer'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c8242ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = model.with_structured_output(AnswerWithJustification)\n",
    "\n",
    "response = structured_llm.invoke(\"\"\"What weighs more, a pound of bricks or a pound \n",
    "    of feathers\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e969771f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'A pound of bricks and a pound of feathers weigh the same---one pound. The difference is in the volume they occupy. Bricks are much denser than feathers, so a pound of bricks takes up less space than a pound of feathers.',\n",
       " 'justification': 'Both objects are measured in pounds, which is a unit of weight. Therefore, by definition, they weigh the same, even though they have very different densities and volumes.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f359e",
   "metadata": {},
   "source": [
    "### Testing with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d276b64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Both weigh the same. The weight is not dependent on the volume or material.',\n",
       " 'justification': 'In both cases, one pound of mass corresponds to approximately 450 grams of matter. The difference lies in their density and composition; feathers are much lighter per unit volume compared to bricks made of heavier materials like brick or concrete.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "ollama_model = ChatOllama(\n",
    "    base_url='http://127.0.0.1:11434',\n",
    "    model=\"deepseek-r1:1.5b\"\n",
    ")\n",
    "\n",
    "ollama_structured = ollama_model.with_structured_output(AnswerWithJustification)\n",
    "response = ollama_structured.invoke(\"\"\"What weighs more, a pound of bricks or a pound \n",
    "    of feathers\"\"\")\n",
    "\n",
    "dict(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483478e9",
   "metadata": {},
   "source": [
    "## Other Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06893877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'banana', 'cherry']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "items = parser.invoke(\"apple, banana, cherry\")\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78bc0738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only Hi\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today? 😊\n",
      "\n",
      "\n",
      "Hi and Bye Lists\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today? 😊\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hey! How's it going? Anything on your mind or need help with anything? 😊\n",
      "\n",
      "\n",
      "Stream\n",
      "<think> \n",
      "\n",
      " </think> \n",
      "\n",
      " Hey !  👋  How 's  it  going ?  Anything  on  your  mind  or  need  help  with  anything ?  "
     ]
    }
   ],
   "source": [
    "print(\"Only Hi\")\n",
    "completion = ollama_model.invoke('Hi there!') \n",
    "print(completion.content)\n",
    "print()\n",
    "print()\n",
    "print(\"Hi and Bye Lists\")\n",
    "completions = ollama_model.batch(['Hi there!', 'Bye!'])\n",
    "print(completions[0].content)\n",
    "print(completions[1].content)\n",
    "print()\n",
    "print()\n",
    "print(\"Stream\")\n",
    "for token in ollama_model.stream('Bye!'):\n",
    "    print(token.content, end=' ', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc957395",
   "metadata": {},
   "source": [
    "## Imperative vs Declarative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7852713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There are several providers that offer Large Language Models (LLMs). Here are some of the notable ones:\\n\\n1. **OpenAI**: They are known for models like GPT-3, GPT-3.5, and GPT-4.\\n\\n2. **Google (DeepMind)**: Google offers models like PaLM (Pathways Language Model) and LaMDA (Language Model for Dialogue Applications).\\n\\n3. **Microsoft**: Microsoft has partnered with OpenAI and also offers models like the one powering Bing Chat.\\n\\n4. **Meta (formerly Facebook)**: Meta has released LLaMA (Large Language Model Meta AI), a foundational large language model designed to help researchers advance their work in the field of AI.\\n\\n5. **Anthropic**: They have developed models like Claude, which is designed to be helpful, honest, and harmless.\\n\\n6. **Mistral AI**: They offer models like Mixtral 8x7B and Mixtral 8x22B.\\n\\n7. **Cohere**: They provide models that are optimized for specific use cases and industries.\\n\\n8. **NVIDIA**: NVIDIA offers models like NeMo, which is designed for conversational AI applications.\\n\\n9. **Aleph Alpha**: They have developed models like Luminous, which is designed for enterprise and government use cases.\\n\\n10. **Mistral AI**: They offer models like Mixtral 8x7B and Mixtral 8x22B.\\n\\n11. **Mistral AI**: They offer models like Mixtral 8x7B and Mixtral 8x22B.\\n\\nThese providers offer a range of models with varying capabilities, sizes, and specializations. The choice of model often depends on the specific use case, the level of detail required, and the resources available.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 373, 'prompt_tokens': 18, 'total_tokens': 391, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'mistralai/mistral-small-3.2-24b-instruct:free', 'system_fingerprint': None, 'id': 'gen-1753278442-aoUVR4WJNjPsbvTXJnLZ', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--eb7bb5de-3c20-4811-b659-bd75489653e2-0', usage_metadata={'input_tokens': 18, 'output_tokens': 373, 'total_tokens': 391, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imperative\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "# the building blocks\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant.'),\n",
    "    ('human', '{question}'),\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    base_url=url,\n",
    "    api_key=apikey,\n",
    "    model=model_sel\n",
    ")\n",
    "\n",
    "# combine them in a function\n",
    "# @chain decorator adds the same Runnable interface for any function you write\n",
    "\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    return model.invoke(prompt)\n",
    "\n",
    "# use it\n",
    "\n",
    "chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10bd29ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Several' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' companies' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' organizations' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' offer' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' large' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='LL' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Ms' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=').' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Here' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' are' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' some' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' notable' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' providers' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=':\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='1' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Open' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='AI' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Known' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' like' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' G' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='PT' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='-' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='3' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' G' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='PT' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='-' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='3' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='5' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' G' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='PT' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='-' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='4' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' which' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' are' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' state' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='-of' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='-the' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='-art' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='2' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Google' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Deep' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Mind' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=')**:' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Off' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ers' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' like' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Pa' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Path' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ways' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Model' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=')' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' more' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' recent' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Pa' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' ' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='2' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' which' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' designed' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' mult' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='iling' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ual' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' capabilities' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' improved' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' performance' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='3' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Meta' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='formerly' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Facebook' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=')**:' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Prov' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ides' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' such' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' as' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='La' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='MA' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Large' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Model' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Meta' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' AI' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=')' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' its' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' versions' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' like' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='La' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='MA' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' ' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='2' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' which' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' are' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' designed' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' research' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' commercial' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' use' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='4' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Microsoft' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Collabor' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ates' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' with' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Open' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='AI' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' offers' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Azure' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='-based' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' integrating' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Open' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='AI' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=\"'s\" additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' into' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' its' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Azure' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' AI' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' services' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='5' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='H' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ug' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ging' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Face' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Host' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='s' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' wide' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' variety' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' open' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='-source' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' provides' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' platforms' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' training' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' deploying' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' these' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='6' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='C' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='oh' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ere' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Off' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ers' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' large' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' tailored' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' enterprise' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' use' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' focusing' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' on' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' generating' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' high' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='-quality' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' text' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='7' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='AI' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='2' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='1' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Labs' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Prov' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ides' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' like' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Jur' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='assic' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' its' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' subsequent' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' versions' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' designed' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' range' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' tasks' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='8' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Alarm' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Develop' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='s' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' offers' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' large' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' various' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' applications' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='9' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='N' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='LP' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Cloud' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Prov' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ides' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' APIs' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' various' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' pre' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='-trained' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' large' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='1' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='0' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='St' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ability' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' AI' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Known' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' its' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' work' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' in' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' gener' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ative' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' AI' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' including' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='1' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='1' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='M' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='osa' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ic' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ML' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' Focus' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='es' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' on' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' developing' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' efficient' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' scalable' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='1' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='2' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Big' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='Science' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' A' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' collaborative' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' project' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' involving' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' many' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' researchers' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' organizations' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' aiming' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' create' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' large' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' through' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' open' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' science' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='These' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' providers' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' offer' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' range' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' with' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' different' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' capabilities' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' fine' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='-t' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='uning' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' options' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' use' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' cases' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' cater' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='ing' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' various' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' industries' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content=' applications' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'mistralai/mistral-small-3.2-24b-instruct:free'} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702'\n",
      "content='' additional_kwargs={} response_metadata={} id='run--8f992055-0a3e-495d-8f30-ca8e769ec702' usage_metadata={'input_tokens': 18, 'output_tokens': 376, 'total_tokens': 394, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "## Streaming\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    for token in model.stream(prompt):\n",
    "        yield token\n",
    "\n",
    "for part in chatbot.stream({\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "}):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f16264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"There are several providers that offer large language models (LLMs). Here are some notable ones:\\n\\n1. **OpenAI**: Known for models like GPT-3, GPT-3.5, and GPT-4.\\n2. **Anthropic**: Offers models like Claude.\\n3. **Google (DeepMind)**:** Provides models such as PaLM and LaMDA.\\n4. **Meta (formerly Facebook)**: Known for LLaMA(Large Language Model Meta AI) and OPT (Open Pre-trained Transformers).\\n5. **Microsoft**: Offers models like those based on OpenAI's technology, integrated into Azure.\\n6. **AWS (Amazon Web Services)**: Provides Amazon Bedrock with models like Anthropic's Claude and AI21 Labs' Jurassic.\\n7. **Mistral AI**: Known for models such as Mistral Large and Mixtral 8x7B.\\n8. **AI21 Labs**: Provides models like Jurassic.\\n9. **NVIDIA**: Offers models such as Megatron-Turing NLG.\\n10. **Hugging Face**: Provides a wide range of open-source models and tools for working with LLMs.\\n\\nThese providers offer a mix of open-source and proprietary models, catering to various use cases and industries.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 270, 'prompt_tokens': 18, 'total_tokens': 288, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'mistralai/mistral-small-3.2-24b-instruct:free', 'system_fingerprint': None, 'id': 'gen-1753279459-OHlMqOYc3kNIQqqPTk19', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--2372838c-f546-464d-aaee-08f4671cf33e-0', usage_metadata={'input_tokens': 18, 'output_tokens': 270, 'total_tokens': 288, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declarative\n",
    "chatbot = template | model\n",
    "chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})\n",
    "##Same with stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0220f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
